nrow(f2[is.na(f2$Country_name),]) #  57 - 31 = 26
nrow(f2[is.na(f2$latitude),]) #  should still be 171
j<-f2[is.na(f2$latitude),]
#junk$nm[junk$nm == "B"] <- "b"
f2$latitude[f2$Country_name == "Europe"] <- 49.606416
# MANUALLY GEOCODE  Mediterranean Sea and Europe-using coords that I estimated from google maps
f2$latitude[f2$Country_name == "Europe"] <- 49.606416
f2$longitude[f2$Country_name == "Europe"] <- 13.792090
f2$latitude[f2$Country_name == "Mediterranean Sea"] <- 35.837359
f2$longitude[f2$Country_name == "Mediterranean Sea"] <- 17.984692
# Final check
nrow(f2[is.na(f2$Country_name),]) #  26
nrow(f2[is.na(f2$latitude),]) # 26
nrow(f2[is.na(f2$longitude),]) # 26
nrow(f2[is.na(f2$Post_Location),]) # 0
nrow(f2[is.na(f2$post_loc_search),]) # 0
################################################################################################
# Check our counts
country_counts<- data.frame(table(d10$Country_name))
#How many unique Post_locations  do we have
length(unique(f2$Post_Location)) # 587
#How many records in f2?
nrow(f2) # 5931
# How many facebook posts?
length(unique(f2$X)) # 5493
# Note, IDs (X) are repeated if > 1 country in Post Location!
## SAVE TO FILE
write.csv(f2, file="output_data/fbpostlocs_geocoded_by_country_5931recs.csv",row.names=F)
## Save a lookup file of the unique post_locs without the FB post id's (X)
f3<-f2[c("Post_Location","post_loc_search","Country_name","longitude","latitude")]
#Remove duplicate rows
f4 <- f3[!duplicated(f3),]
nrow(f4) # should be greater than or equal to length(unique(f2$Post_Location)) # 587
# since we exploded the Post_locs to one country per row
write.csv(f4, file="output_data/fbpostlocs_unique_countries_815.csv",row.names=F)
################################################################################################
# So we now have our geo data at the country level for all unique Post Locations.
# This includes X (the post ID), post_loc_search, Country_name,
#         latitude and longitude for each Post Location
################################################################################################
#TODO
# 1. reconcile country data for above 26 odd cases without Country_name, lat & lon (eg Timor Sea)
# 2. merge in with big fb dataset
# 3. first clean the fb dataset and reshape as we need it.
# NOT DONE
# Clean up the county data - THE POST_LOCATIONS have nasty bits that may have been copied
# to post_loc_search and Country_name
# f2$Country_name <-gsub("[\r\n]", "", f2$Country_name)
# f2$Country_name <- gsub("[\n]", "", f2$Country_name)
# f2$Country_name<- trimws( f2$Country_name)
#
# This script
# Reades in the complete cleaned facebook file
# and does a bit more cleaning
# of the columns we want to visualize
# by making sure the range of values for each variable is consistent
#
# input file is: Facebook_Complete_CLEAN.csv
# output file is: Facebook_Complete_CLEAN_pattyclean_v2.csv
setwd("~/Documents/Dlab/projects/citris_refuge/march2018/facebook_all_clean_v2")
library(dplyr)
library(readxl)
library(tidyr)
p1 <- read.csv("source_data/Facebook_Complete_CLEAN.csv", strip.white = T, stringsAsFactors = F)
p1_colnames <- names(p1)
p1_colnames
# Subset out only the cols we want to work with initially
get_cols <- c("Group_Num","X","Status_Identifier","Date","Post_Location",
"Theme_Smugglers","Theme_Family_Reunification", "Theme_National_Asylum_Policy","Theme_Nation",
"Sentiment_Smuggler","Sentiment_Govt_Officials","Sentiment_Aid_Orgs", "Ethnicity_Sentiment", #"Ethnicity_Migrant"
"Disturbing_Event", "Tone_General","Tone_Detailed")
p2 <- p1[,get_cols]
################################################################################
# RECODE DATA VALUES to range of valid values
################################################################################
# Recode Theme_Smugglers such that if not 1 then zero (not mentioned)
p2$Theme_Smugglers[is.na(p2$Theme_Smugglers)] <- 0  # set NAs to zero
p2$Theme_Smugglers <- ifelse(p2$Theme_Smugglers  == 1, 1, 0) # set any value not 1 to zero
table(p2$Theme_Smugglers)
# Recode Theme_Family_Reunification such that if not 1 then zero (not mentioned)
p2$Theme_Family_Reunification[is.na(p2$Theme_Family_Reunification)] <- 0  # set NAs to zero
p2$Theme_Family_Reunification <- ifelse(p2$Theme_Family_Reunification  == 1, 1, 0) # set any value not 1 to zero
table(p2$Theme_Family_Reunification)
# #Theme_National_Asylum_Policy
p2$Theme_National_Asylum_Policy[is.na(p2$Theme_National_Asylum_Policy)] <- 0  # set NAs to zero
p2$Theme_National_Asylum_Policy <- ifelse(p2$Theme_National_Asylum_Policy  == 1, 1, 0) # set any value not 1 to zero
table(p2$Theme_National_Asylum_Policy)
#"Sentiment_Smuggler" - 0 (not mentioned), 1 (neg), 2 (neutral) or 3 (pos)
p2<- p2 %>%
mutate(Sentiment_Smuggler  = if_else( Sentiment_Smuggler %in% c("1","2","3"), Sentiment_Smuggler, "0" ))
p2$Sentiment_Smuggler <- as.numeric(p2$Sentiment_Smuggler)
unique(p2$Sentiment_Smuggler)
table(p2$Sentiment_Smuggler)
summary(p2$Sentiment_Smuggler)
#"Sentiment_Govt_Officials",
p2<- p2 %>%
mutate(Sentiment_Govt_Officials  = if_else( Sentiment_Govt_Officials %in% c("1","2","3"), Sentiment_Govt_Officials, "0" ))
p2$Sentiment_Govt_Officials <- as.numeric(p2$Sentiment_Govt_Officials)
unique(p2$Sentiment_Govt_Officials)
table(p2$Sentiment_Govt_Officials)
summary(p2$Sentiment_Govt_Officials)
#"Sentiment_Aid_Orgs",
p2<- p2 %>%
mutate(Sentiment_Aid_Orgs  = if_else( Sentiment_Aid_Orgs %in% c("1","2","3"), Sentiment_Aid_Orgs, "0" ))
p2$Sentiment_Aid_Orgs <- as.numeric(p2$Sentiment_Aid_Orgs)
unique(p2$Sentiment_Aid_Orgs)
table(p2$Sentiment_Aid_Orgs)
#"Ethnicity_Sentiment", Ethnicity_Migrant
# SAVE FOR LATER...complicated
#"Disturbing_Event", - 1 (discusses one) 0 - does not mention
# SHOULD recode x=9419 and 8065 from 2 to 1 since 2 not valid
p2<- p2 %>%
mutate(Disturbing_Event  = if_else( Disturbing_Event == 1, 1, 0 ))
p2<- p2 %>%
mutate(Disturbing_Event  = if_else(is.na(Disturbing_Event ), 0, Disturbing_Event ))
unique(p2$Disturbing_Event)
table(p2$Disturbing_Event)
summary(p2$Disturbing_Event)
#"Tone_General",
# 1 - The overall tone is negative
# 2 - The overall tone is neutral (i.e. an inquiry, etc.)
# 3 - The overall tone is positive (i.e. expresses hope, optimism, or discusses compete
p2 <- p2 %>% mutate(Tone_General  = if_else( Tone_General %in% c("1","2","3"), Tone_General, "0" ))
p2$Tone_General <- as.numeric(p2$Tone_General)
unique(p2$Tone_General)
summary(p2$Tone_General)
str(p2)
# Tone_Detailed
table(p2$Tone_Detailed)
p2 <- p2 %>% mutate(Tone_Detailed  = if_else( Tone_Detailed %in% c("1","2","3","4","5"), Tone_Detailed, "0" ))
p2$Tone_Detailed <- as.numeric(p2$Tone_Detailed)
unique(p2$Tone_Detailed)
summary(p2$Tone_Detailed)
str(p2)
## THIS FILE IS THE CLEANED UP FACEBOOK FILE for ANALYSIS/VISUALIZATION
write.csv(p2, file="output_data/Facebook_Complete_CLEAN_pattyclean_v2.csv", row.names = F)
nrow(p2)
#
# This script to check the geodata values
# joins the geographic data at the county leve
# to the facebook posts
#
# FB Posts data input file is: Facebook_Complete_CLEAN_pattyclean_v2.csv
# Geo input file is:           fbpostlocs_geocoded_by_country_5931recs.csv
#
# output file is:              Facebook_Complete_CLEAN_pattyclean_v2_wgeo.csv
setwd("~/Documents/Dlab/projects/citris_refuge/march2018/facebook_all_clean_v2")
geodata<-read.csv("output_data/fbpostlocs_geocoded_by_country_5931recs.csv", stringsAsFactors = F, strip.white = T)
#CHECK IT
geo_df <- data.frame(table(geodata$Country_Geo))
fbdata<- read.csv("output_data/Facebook_Complete_CLEAN_pattyclean_v2.csv", stringsAsFactors = F, strip.white = T)
a<-unique(fbdata$X)  # X us the facebook post unique id
b<-unique(geodata$X)
# All of the Xs in b should be in a (but not vis versa as a>b)
setdiff(b,a)
# Merge the geo data with the FB post data by Post ID (X)
names(geodata) #"Post_Location" "X" "Country_name" "post_loc_search" "latitude" "longitude"
colnames(geodata) <- c("Post_Location_geo", "Xgeo","Country_name","post_loc_search" ,"latitude" ,"longitude")
nrow(geodata)
nrow(fbdata)
fbdata_wgeo <- merge(fbdata,geodata, by.x="X", by.y="Xgeo", all.x=T)
# Sanity checks - do we have what we should have
num_data_rows <- nrow(fbdata_wgeo) # How many total rows?
num_fbposts <- length(unique(fbdata_wgeo$X)) # Unique IDS - should be 10642
num_fbposts_wPostLoc<- nrow(fbdata_wgeo[is.na(fbdata_wgeo$Post_Location_geo),]) # How many posts have a Post_Location: Stavros says should be 5149 ; Patty gets 5149
#How many posts have been geocoded at the country level
num_fbposts_wPostLoc_wCountryGeo <- length(unique(fbdata_wgeo[!is.na(fbdata_wgeo$Country_name),]$X))
num_fbposts_wPostLoc_wCountryGeo
# differences is numbers due to the odd cases where the post had no "country":
# Europe: 122, Med Sea 31, Balkans 9, Asia 2, Eastern europe 2, Middle east 2,
# Channel tunnel 1, Maritsa river 1, South Asia1 , Timor Sea 1
# BUT - we manually coded the country for Europe/EU/Eastern Europe > Europe and Med Sea to Med Sea
# Save IT then no need to run above code
write.csv(fbdata_wgeo, file="output_data/Facebook_Complete_CLEAN_pattyclean_v2_wgeo.csv",row.names=F)
#
# Prepare facebook post with geo data for visualization
# by transforming the data from wide to long column format
#
# Input file: Facebook_Complete_CLEAN_pattyclean_v2_wgeo.csv
# Output file: Facebook_Complete_CLEAN_pattyclean_v2_wgeo_long.csv
#
library(dplyr)
setwd("~/Documents/Dlab/projects/citris_refuge/march2018/facebook_all_clean_v2")
#############################################################################################
# Prepare data for Viz by transforming wide col format to long col format
#############################################################################################
fbdata<-read.csv("output_data/Facebook_Complete_CLEAN_pattyclean_v2_wgeo.csv", stringsAsFactors = F)
the_cols <- names(fbdata)
the_cols
# Gather theme cols 6-8
# "Theme_Smugglers" , "Theme_Family_Reunification"   "Theme_National_Asylum_Policy"
fb2 <-gather(fbdata, "theme", "theme_mentioned", 6:8)
#check it
table(fb2[fb2$theme_mentioned==1,]$theme)
# Gather Sentiment cols 7-9
# "Sentiment_Smuggler"           "Sentiment_Govt_Officials"     "Sentiment_Aid_Orgs"
fb2 <- gather(fb2, "sentiment","sentiment_code",7:10)
# Save it
write.csv(fb2, file="output_data/Facebook_Complete_CLEAN_pattyclean_v2_wgeo_long.csv",row.names=F)
########################################
# Need to go back and add numlikes etc
#######################################
# hist(f1$num_likes[f1$num_likes> 20])
# hist(f1$num_likes[f1$num_likes> 100])
# hist(f1$num_likes[f1$num_likes> 1000])
#
library(ggplot2)
library(ggmap)
setwd("~/Documents/Dlab/workshops/2018/rgeo_may2018/r-geospatial-workshop")
police_stations <- read.csv("data/sf_police_addresses.csv")
police_stations <- read.csv("data/sf_police_addresses.csv", stringsAsFactors = F, strip.white = T)
head(police_stations)
geocode(police_stations)
?geocode
police_stations$full_address <- paste(police_stations$Address, police_stations$City, police_stations$State)
head(police_stations)
x<- geocode(police_stations$full_address)
x
police_stations <- cbind(police_stations, x)
head(police_stations)
setwd("~/Documents/Dlab/workshops/2018/rgeo_may2018/r-geospatial-workshop")
dir()
dir("data")
clear
dir("images")
setwd("~/Documents/Dlab/workshops/2018/rgeo_may2018/r-geospatial-workshop")
setwd("~/Documents/Dlab/workshops/2018/rgeo_may2018/r-geospatial-workshop")
str(sfhomes)
sfhomes <- read.csv('data/sf_properties_25ksample.csv', stringsAsFactors = FALSE)
str(sfhomes)
summary(sfhomes$FiscalYear)
summary(SupeDistrict)
summary(sfhomes$SupeDistrict)
table(as.character(sfhomes$SupeDistrict))
head(sfhomes,6)
knitr::opts_chunk$set(echo = TRUE)
sfhomes[1:5,c("SalesYear","totvalue","Neighborhood")]
sfhomes[1:5,c("YearBuilt","totvalue","Neighborhood")]
sfhomes[1:5,c("YearBuilt","totvalue","Neighborhood","NumBedrooms","NumBathrooms")]
sfhomes[1:5,c("YearBuilt","totvalue","Neighborhood","NumBedrooms","NumBathrooms")]
sfhomes[1:5,c("YearBuilt","totvalue","AreaSquareFeet","Neighborhood","NumBedrooms","NumBathrooms")]
sfhomes[1:5,c("YearBuilt","SalesYear","totvalue","AreaSquareFeet","Neighborhood","NumBedrooms","NumBathrooms")]
summary(sfhomes(SalesYear))
summary(sfhomes$SalesYear)
table(sfhomes$SalesYear)
hist(sfhomes$totvalue)
library(ggplot2)
library(ggmap)
sf_map <- get_map("San Francisco, CA")
sf_map <- get_map("San Francisco, CA")
?register_google
has_goog_key()
register_google(key="AIzaSyCqyzbTvMq2XEYr6CBqS3PcNxkONdeHyhA")
has_goog_key()
sf_map <- get_map("San Francisco, CA")
sf_map <- get_map("San Francisco, CA")
sf_map <- get_map("San Francisco, CA")
register_google(key="AIzaSyCqyzbTvMq2XEYr6CBqS3PcNxkONdeHyhA")
query_limit()
?geocode
geocodeQueryCheck()
sf_map <- get_map("San Francisco, CA")
?get_map
sf_map <- get_map("San Francisco, CA")
register_google(key="AIzaSyBE23PnI3bzQBJkhXuhXTenSfwwOVH6xUo")
geocodeQueryCheck()
sf_map <- get_map("San Francisco, CA")
sf_map <- get_map("San Francisco, CA")
sf_map <- get_map("San Francisco, CA")
register_google(key="AIzaSyBE23PnI3bzQBJkhXuhXTenSfwwOVH6xUo")
sf_map <- get_map("San Francisco, CA")
ggplot() + geom_point(data=sfhomes, aes(lon,lat)) + coord_map()
ggplot() + geom_point(data=sfhomes, aes(lon,lat), size=1) #+ coord_map()
ggplot() + geom_point(data=sfhomes, aes(lon,lat, col=totvalue)) +
coord_map()
sfhomes_low2high <- sfhomes[order(sfhomes$totvalue, decreasing = FALSE),]
ggplot() +
geom_point(data=sfhomes_low2high, aes(lon,lat, col=totvalue)) +
coord_map()
sfhomes_low2high <- sfhomes[order(sfhomes$totvalue, decreasing = FALSE),]
ggplot() +
geom_point(data=sfhomes_low2high, aes(lon,lat, col=totvalue)) +
coord_map()
sfhomes_high2low <- sfhomes[order(sfhomes$totvalue, decreasing = T),]
ggplot() + geom_point(data=sfhomes_high2low, aes(lon,lat, col=totvalue)) +
coord_map()
sfhomes2010_15 <- subset(sfhomes_low2high, as.numeric(SalesYear) > 2009)
ggplot() +
geom_point(aes(lon, lat, col=totvalue), data = sfhomes2010_15 )  +
facet_wrap(~ SalesYear)
sf_map <- get_map("San Francisco, CA")
sf_map <- get_map("San Francisco, CA")
register_google(key="AIzaSyBE23PnI3bzQBJkhXuhXTenSfwwOVH6xUo")
sf_map <- get_map("San Francisco, CA")
police_stations <- read.csv("data/sf_police_addresses.csv", stringsAsFactors = F)
head(police_stations)
geocode(police_stations)
?geocode
```{r}
police_stations$full_address <- paste(police_stations$Address,
police_stations$City, police_stations$State)
head(police_stations)
station_coords <- geocode(police_stations$full_address)
police_stations <- cbind(police_stations, station_coords)
head(police_stations)
police_stations[1:5,c("PoliceDistrict","full_address","lon","lat")]
sf_map <- get_map("San Francisco, CA", source="osm")
sf_map <- get_map("San Francisco, CA", source="osm")
?get_map
sf_map <- get_map("San Francisco, CA", source="osm")
sf_map <- get_map("San Francisco, CA")
ggmap(sf_map)
police_stations <- read.csv("data/sf_police_addresses.csv", stringsAsFactors = F)
head(police_stations)
summary(sfhomes$SalesYear)
50-38
38+12
landmarks
bart <- read.csv("./data/bart.csv")
landmarks <- read.csv("./data/landmarks.csv")
head(bart)
head(landmarks)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), col="green")
# FIRST - subset the data
sfhomes15 <- subset(sfhomes, as.numeric(SalesYear) == 2015)
# Get the center point of the data
sf_ctr <- c(lon = mean(sfhomes15$lon), lat = mean(sfhomes15$lat))
sf_ctr  # take a look
# create the map
sf_basemap <- get_map(sf_ctr, zoom=12, scale=1)
station_coords <- geocode(police_stations$full_address)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), col="green")
```{r, eval=F}
police_stations <- read.csv("data/sf_police_addresses.csv", stringsAsFactors = F)
head(police_stations)
geocode(police_stations)
?geocode
police_stations$full_address <- paste(police_stations$Address,
police_stations$City, police_stations$State)
head(police_stations)
station_coords <- geocode(police_stations$full_address)
station_coords <- geocode(police_stations$full_address)
police_stations <- cbind(police_stations, station_coords)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), col="green")
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), col="purple")
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat), col="purple")  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), col="black")
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat), col="purple")  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), col="black", size=2)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat), col="purple")  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), col="black", size=2, shape="square")
?geom_point
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), col="orange", size=2)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), col="darkgreen", size=2)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), col="green", size=2)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), col="white", size=2)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), col="grey", size=2)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), col="orange", size=2)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), shape=22, col="orange", size=2)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), shape=22, col="grey", fill="orange" size=2)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), shape=22, col="grey", fill="orange", size=2)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
geom_point(data=police_stations, aes(x=lon,y=lat), shape=22, col="grey", fill="orange", size=6)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red", size=4) +
geom_point(data=police_stations, aes(x=lon,y=lat), shape=22, col="grey", fill="orange", size=6)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red", size=3) +
geom_point(data=police_stations, aes(x=lon,y=lat), shape=22, col="grey", fill="orange", size=6)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red", size=3) +
geom_point(data=police_stations, aes(x=lon,y=lat), shape=22, col="grey", fill="orange", size=4)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red", size=2) +
geom_point(data=police_stations, aes(x=lon,y=lat), shape=22, col="grey", fill="orange", size=3)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="purple", size=3) +
geom_point(data=police_stations, aes(x=lon,y=lat), shape=22,
col="grey", fill="orange", size=2)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="purple", size=3) +
geom_point(data=police_stations, aes(x=lon,y=lat), shape=22,
col="grey", fill="green", size=2)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="purple", size=3) +
geom_point(data=police_stations, aes(x=lon,y=lat), shape=22,
col="grey", fill="brown", size=2)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="purple", size=3) +
geom_point(data=police_stations, aes(x=lon,y=lat), shape=22,
col="grey", fill="brown", size=4)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red", size=3) +
geom_point(data=police_stations, aes(x=lon,y=lat), shape=22,
col="grey", fill="brown", size=4)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red", size=3) +
geom_point(data=police_stations, aes(x=lon,y=lat), shape=22,
col="grey", fill="grey", size=4)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red", size=3) +
geom_point(data=police_stations, aes(x=lon,y=lat), shape=22,
col="black", fill="grey", size=4)
head(landmarks)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red") +
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red")
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red")
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red")
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red", size=3) +
geom_point(data=landmarks, aes(x=lon,y=lat), shape=22,
col="black", fill="grey", size=4)
ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red", size=3) +
geom_point(data=landmarks, aes(x=X,y=Y), shape=22,
col="black", fill="grey", size=4)
ggmap(sf_map) +
geom_point(data=sfhomes, aes(x=lon, y=lat, col=totvalue))
ggmap(sf_map) +
geom_point(data=sfhomes, aes(x=lon, y=lat, col=totvalue))
ggmap(sf_map) + geom_point(sfhomes, aes(x=lon, y=lat, col=totvalue))
ggmap(sf_map) + geom_point(data=sfhomes, aes(x=lon, y=lat, col=totvalue))
ggmap(sf_map) + geom_point(sfhomes, aes(x=lon, y=lat, col=totvalue))
ggmap(sf_map) + geom_point(data=sfhomes, aes(x=lon, y=lat, col=totvalue))
ggplot() + geom_point(data=sfhomes, aes(x=lon, y=lat, col=totvalue))
ggplot(sfhomes) + geom_point( aes(x=lon, y=lat, col=totvalue))
class(sf_ctr)
typeof(sf_ctr)
sf_ctr
sf_ctr[1]
sf_ctr[2]
sf_ctr[[2]]
sf_ctr2<-c(mean(sfhomes$lon), mean(sfhomes$lat))
sfbasemap2 <-get_map(sf_ctr2)
ggmap(sf_ctr2)
ggmap(sfbasemap2)
bart <- read.csv("./data/bart.csv")
head (bart)
library(knitr)
purl("r-geospatial-workshop-pt1.Rmd",
output = "scripts/r-geospatial-workshop-pt1.R", documentation = 1)
