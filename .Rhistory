homes_with_tracts <- over(sfhomes15_utm, sftracts_utm)
homes_with_tracts <- over(sfhomes15_utm, sftracts_utm)
class(homes_with_tracts)
nrow(homes_with_tracts)
nrow(sftracts_utm)
nrow(sfhomes15_utm)
head(homes_with_tracts)
sfhomes15_utm$home_geoid <- homes_with_tracts$GEOID
# Review and note the change
#head(sfhomes15_utm@data)
med_hh_inc <- read.csv("data/sf_med_hh_income2015.csv", stringsAsFactors = F,
colClasses = c("character","numeric"))
head(med_hh_inc)
sfhomes15_utm <- merge(sfhomes15_utm,
med_hh_inc, by.x="home_geoid", by.y="GEOID")
head(sfhomes15_utm@data, 2)  # take a look with View(sfhomes15_utm@data)
sfhomes15_utm <- merge(sfhomes15_utm,
med_hh_inc, by.x="home_geoid", by.y="GEOID")
head(sfhomes15_utm@data, 2)  # take a look with View(sfhomes15_utm@data)
tmap_mode("view")
tm_shape(sfhomes15_utm) + tm_dots(col="medhhinc")
tmap_mode("view")
tm_shape(sfhomes15_utm) + tm_dots(col="medhhinc.x")
tmap_mode("plot")
tracts_with_mean_val <- aggregate(x = sfhomes15_utm["totvalue"],
by = sftracts_utm, FUN = mean)
class(tracts_with_mean_val)
head(tracts_with_mean_val@data)
nrow(tracts_with_mean_val) == nrow(sftracts_utm)
sftracts_utm$mean_totvalue <- tracts_with_mean_val$totvalue
head(sftracts_utm@data) # check it
tmap_mode("view")
tm_shape(sftracts_utm) +
tm_polygons(col="mean_totvalue", border.col=NA)
tm_shape(sftracts_utm) +
tm_polygons(col="mean_totvalue", border.col=NA) +
tm_shape(sfhomes15_utm) + tm_dots()
bart_1km_buffer <- gBuffer(sfbart_utm, width=1000)
tmap_mode("view")
tm_shape(bart_1km_buffer) + tm_polygons(col="red") +
tm_shape(sfbart_utm) + tm_dots()
bart_1km_buffer_byid <- gBuffer(sfbart_utm, width=1000, byid=TRUE)
tmap_mode("view")
tm_shape(bart_1km_buffer_byid) + tm_polygons(col="red") +
tm_shape(sfbart_utm) + tm_dots()
homes_near_bart <-  gIntersects(bart_1km_buffer, sfhomes15_utm, byid=TRUE)
class(homes_near_bart)
head(homes_near_bart)
# subset
sfhomes15_utm_near_bart <- sfhomes15_utm[as.vector(homes_near_bart),]
tm_shape(bart_1km_buffer) + tm_polygons(col="red") +
tm_shape(sfhomes15_utm_near_bart) + tm_dots()
library(sp)     # spatial objects and methods
library(rgdal)  # read/write from file; manage CRSs
library(rgeos)  # geometric operations
library(tmap)   # mapping spatial objects
library(raster) # reading in and operating on rasters
path = "/path/to/your/working_directory"
setwd(path)
# Read in the 'sftracts_wpop' shapefile
tracts = readOGR('./data', 'sftracts_wpop')
# Read in from CSV file
print(list.files())
sfhomes <- read.csv('./data/sf_properties.csv',
stringsAsFactors = FALSE)
# subset the data
sfhomes15 <- subset(sfhomes, as.numeric(SalesYear) == 2015)
sfhomes15_sp <- sfhomes15  # Make a copy
# Make it spatial
coordinates(sfhomes15_sp) <- c('lon','lat')
#Assign it a proj4string using the EPSG code
proj4string(sfhomes15_sp) <- CRS("+init=epsg:4326")
#Reproject to the tracts projection
#NOTE: We're overwriting the previous sfhomes15_sp object here! This is
#fine to do if we want, but we should always beware.
sfhomes15_sp = spTransform(sfhomes15_sp, CRS(proj4string(tracts)))
#check projection equality
proj4string(sfhomes15_sp) == proj4string(tracts)
# Reading in and plotting raster files
#read in a Bay Area DEM (Digital Elevation Model)
#(from http://www.webgis.com/terr_pages/CA/dem1/sanfrancisco.html)
DEM = raster('./data/san_francisco-e.DEM')
#plot it
plot(DEM)
DEM
tracts
DEM@extent
DEM@crs
DEM@ncols
tracts@bbox
tracts@proj4string
(DEM@extent@xmax - DEM@extent@xmin) / DEM@ncols
(DEM@extent@ymax - DEM@extent@ymin) / DEM@nrows
DEM
DEM@data
DEM@data@values
DEM@data@inmemory
DEM@data@fromdisk
DEM[10:15, 20:30]
DEM[,]
#coerce our whole raser's dataset to a matrix, with the appropriate number
#of columns, and
matrix(DEM[,], ncol = ncol(DEM), byrow = TRUE)
test = raster(matrix(DEM[,], ncol = ncol(DEM), byrow = TRUE))
test
DEM[10:15, 20:30, drop = FALSE]
test = DEM[10:15, 20:30, drop = FALSE]
plot(test)
test@data@values
test@data@inmemory
test@data@fromdisk
#check out its projection
proj4string(DEM)
#reproject tracts to our DEM projection
tracts_NAD = spTransform(tracts, CRS(proj4string(DEM)))
DEM_WGS = projectRaster(DEM, projectExtent(DEM, CRS(proj4string(tracts))))
# Now let's check equivalence
proj4string(tracts_NAD) == proj4string(DEM)
proj4string(DEM_WGS) == proj4string(tracts)
# clip the WGS CRS version of the rasters to tracts
DEM_WGS_crop = crop(DEM_WGS, extent(tracts))
# Clip the NAD CRS version
DEM_crop = crop(DEM, extent(tracts_NAD))
plot(DEM_WGS_crop)
#plot together
plot(DEM_WGS_crop)
plot(tracts, add = T)
DEM_WGS_crop_masked = mask(DEM_WGS_crop, tracts)
DEM_WGS_crop_masked
DEM_WGS_crop
plot(DEM_WGS_crop_masked)
plot(tracts, add = T)
my_map <- tm_shape(DEM_WGS_crop_masked) +
tm_raster() +
tm_shape(tracts) +
tm_borders() +
# Set mode to interactive
tmap_mode("view")
my_map
#write our reprojected, cropped data to the data directory, using the Geotiff format
#(and allow R to overwrite if file already exists)
writeRaster(DEM_WGS_crop_masked, filename="./data/DEM_reproject_crop.tif", format="GTiff", overwrite = T)
# get the elevation for every cell in each of the census tracts
elev = extract(DEM_WGS_crop, tracts)
#what did that give us?
head(elev)
length(elev)
nrow(tracts)
mean_elev = lapply(elev, mean, na.rm = T)
head(mean_elev)
tracts$mean_elev = unlist(mean_elev)
#what did we get?
elev_map <- tm_shape(tracts) +
tm_polygons(col = 'mean_elev') +
tm_layout("The pain of biking in SF, by census tract",
inner.margins=c(0,0,.1,0), title.size=4.8)
elev = extract(DEM_WGS_crop, tracts, fun=mean)
#what did that give us?
head(elev)
#read in nlcd data
nlcd = raster('./data/nlcd2011_sf.tif')
#plot nlcd
plot(nlcd)
freq(nlcd)
barplot(nlcd)
#check projection equality
proj4string(nlcd) == proj4string(tracts)
#reproject
nlcd_WGS = projectRaster(nlcd, projectExtent(nlcd, CRS(proj4string(tracts))))
#check projection equality again
proj4string(nlcd_WGS) == proj4string(tracts)
#crop
nlcd_WGS_crop = crop(nlcd_WGS, extent(tracts))
#check projection equality
proj4string(nlcd) == proj4string(tracts)
#reproject
nlcd_WGS = projectRaster(nlcd, projectExtent(nlcd, CRS(proj4string(tracts))))
#check projection equality again
proj4string(nlcd_WGS) == proj4string(tracts)
#crop
nlcd_WGS_crop = crop(nlcd_WGS, extent(tracts))
plot(nlcd_WGS_crop)
nlcd@legend
nlcd_WGS_crop@legend
nlcd_WGS_crop@legend = nlcd@legend
plot(nlcd_WGS_crop)
?reclassify
reclass_df <- c(0, 12, NA, # water will be set to NA (i.e. 'left out' of our analysis)
20, 21, 1, # we'll treat developed open space as greenspace, based on NLCD description
21, 30, 0, # developed and hardscape will have 0s
30, 32, NA,
40, Inf, 1) # greensapce will have 1s
reclass_df
reclass_m <- matrix(reclass_df, ncol = 3, byrow = TRUE)
reclass_m
nlcd_green <- reclassify(nlcd, reclass_m)
freq(nlcd_green)
barplot(nlcd_green)
plot(nlcd_green)
#extract the mean nlcd_simple values to tract polygons
greenspace = c(extract(nlcd_green, tracts, fun=mean))
greenspace
?raster::extract
#extract the mean nlcd_simple values to tract polygons,
#this time setting na.rm to TRUE
greenspace = extract(nlcd_green, tracts, fun=mean, na.rm = T)
#and add to our tracts dataframe (which we can do because order is preserved)
tracts$prop_greenspace = greenspace
#aggregate totvalue to tracts
tracts_w_mean_val = aggregate(x = sfhomes15_sp['totvalue'], by = tracts, FUN = mean)
#use a quick tmap to check that it looks like sensible output
qtm(tracts_w_mean_val, fill = 'totvalue')
#and add the mean_val column to our tracts dataframe
tracts$mean_totvalue = tracts_w_mean_val$totvalue
mod = lm(mean_totvalue ~ mean_elev + prop_greenspace, data = tracts)
summary(mod)
#First, we'll take a random subset of our 2015 homes, so that our analysis doesn't take so long to compute.
sfhomes15_sample = sfhomes15_sp[sample(seq(nrow(sfhomes15_sp)), replace = FALSE, size = 2000), ]
#reproject
sfhomes15_utm <- spTransform(sfhomes15_sample, CRS("+init=epsg:26910"))
DEM_utm = projectRaster(DEM, projectExtent(DEM, CRS(proj4string(sfhomes15_utm))))
nlcd_green_utm = projectRaster(nlcd_green, projectExtent(nlcd_green, CRS(proj4string(sfhomes15_utm))))
#check that the projections are all good
proj4string(sfhomes15_utm) == proj4string(DEM_utm)
proj4string(sfhomes15_utm) == proj4string(nlcd_green_utm)
#create buffer
sfhomes15_utm_buff = gBuffer(sfhomes15_utm, width = 100, byid = T)
#sum the greenspace within the buffers
#NOTE: This will take a couple minutes to run...
greenspace_homes = extract(nlcd_green_utm, sfhomes15_utm_buff, fun = mean, na.rm = T)
#add that as a column in our sfhomes15_utm dataframe
sfhomes15_utm$greenspace = greenspace_homes
#extract the elevation to the homes
#NOTE: no need for fun or na.rm arguments here, because the homes
#and points, not polygons, so only a single cell will extract to each
elev_homes = extract(DEM_utm, sfhomes15_utm)
#add that as a column in our sfhomes15_utm dataframe too
sfhomes15_utm$elev = elev_homes
mod = lm(totvalue ~ elev + greenspace, data = sfhomes15_utm)
summary(mod)
#(from http://climate.calcommons.org/dataset/monthly-summertime-fog)
#(units are in average hours per day)
karl_files = unique(gsub('.aux.xml', '', list.files('./data/CalMnYr')))
karl_files = karl_files[grep('flcc', karl_files)]
# Take  a look
karl_files
karl <- stack(paste0('./data/CalMnYr/', karl_files))
# look at what we made
karl
#plot one
plot(karl[[7]])
plot(tracts, add = T)
#what's the projection?
proj4string(karl)
karl_WGS = projectRaster(karl, projectExtent(karl, CRS(proj4string(tracts))))
# check resultant CRS
proj4string(karl_WGS) == proj4string(tracts)
karl_WGS
# See the documentation!
?raster::brick
# Crop it to tracts
karl_WGS_crop = crop(karl_WGS, extent(tracts))
#Note that R vectorized that operation across our entire RasterBrick, the same way that it vectorizes many operations, e.g. 3<4 vs 3< seq(4)
# now let's make our same plot again
par(mfrow = c(1,2))
plot(karl[[7]])
plot(tracts, add = T)
plot(karl_WGS_crop[[7]])
plot(tracts, add = T)
# Mean values
mean_karl_WGS_crop = mean(karl_WGS_crop)
mean_karl_WGS_crop
plot(mean_karl_WGS_crop)
plot(tracts, add = T)
# This won't work
sd_karl_WGS_crop = sd(karl_WGS_crop)
sd_karl_WGS_crop = calc(karl_WGS_crop, sd)
#plot that too
par(mfrow = c(1,2))
plot(mean_karl_WGS_crop)
plot(tracts, add = T)
plot(sd_karl_WGS_crop)
plot(tracts, add = T)
tracts$mean_karl = extract(mean_karl_WGS_crop, tracts, mean)
# Linear regression model
mod = lm(mean_karl ~ mean_elev, data = tracts)
summary(mod)
#devtools::install_github("dkahle/ggmap")
library(ggmap)
#devtools::install_github("dkahle/ggmap")
library(ggmap)
?getmap
?get_map
?ggmap::ggmap_credentials()
ggmap::hadley
plot(ggmap::hadley)
devtools::install_github("dkahle/ggmap")
read.table('/home/drew/Desktop/gapi.txt')
read.table('/home/drew/Desktop/gapi.txt')[1][1]
register_google(read.table('/home/drew/Desktop/gapi.txt')[1][1])
register_google(as.char(read.table('/home/drew/Desktop/gapi.txt')[1][1]))
register_google(as.character(read.table('/home/drew/Desktop/gapi.txt')[1][1]))
geocode("NYC")
sf_center_point <- c(lon=-122.445144, lat=37.769335 )
sf_map <- get_map(sf_center_point, source="stamen", maptype="toner-lite")
install.packages('stringr')
install.packages("stringr")
register_google(as.character(read.table('/home/drew/Desktop/gapi.txt')[1][1]))
library(ggmap)
register_google(as.character(read.table('/home/drew/Desktop/gapi.txt')[1][1]))
geocode("NYC")
geocode("New York")
register_google('AIzaSyDicOM_CrEQRNKOPEXnuCLtQOuJdYuVXSQ')
geocode("New York")
geocode("Berkeley, CA")
geocode("Coit Tower")
read.csv('/home/drew/Desktop/gapi.txt')
read.csv('/home/drew/Desktop/gapi.txt')[1]
read.csv('/home/drew/Desktop/gapi.txt')[1][1]
read.csv('/home/drew/Desktop/gapi.txt', header = FALSE)[1][1]
read.csv('/home/drew/Desktop/gapi.txt', header = FALSE)
read.csv('/home/drew/Desktop/gapi.txt', header = FALSE)[[1]]
read.csv('/home/drew/Desktop/gapi.txt', header = FALSE)[[1]][1]
read.csv('/home/drew/Desktop/gapi.txt', header = FALSE)[[1]][[1]
]
readChar('/home/drew/Desktop/gapi.txt')
filename = '/home/drew/Desktop/gapi.txt'
readChar(filename, file.info(filename)$size)
readChar(filename, file.info(filename)$size)
gsub('\n', '', readChar(filename, file.info(filename)$size))
filename = '/home/drew/Desktop/gmapi.txt'
register_google(gsub('\n', '', readChar(filename, file.info(filename)$size)))
filename = '/home/drew/Desktop/gmapi.txt'
register_google(gsub('\n', '', readChar(filename, file.info(filename)$size)))
sf_center_point <- c(lon=-122.445144, lat=37.769335 )
sf_map <- get_map(sf_center_point, source="stamen", maptype="toner-lite")
sf_center_point <- c(lon=-122.445144, lat=37.769335 )
sf_map <- get_map(as.array(sf_center_point), source="stamen", maptype="toner-lite")
?get_map
sf_center_point <- c(lon=-122.445144, lat=37.769335 )
sf_map <- get_map(sf_center_point)
sf_center_point <- c(lon=-122.445144, lat=37.769335 )
sf_map <- get_map(sf_center_point)
ggmap(sf_map)
filename = '/home/drew/Desktop/gmapi.txt'
register_google(gsub('\n', '', readChar(filename, file.info(filename)$size)))
sf_center_point <- c(lon=-122.445144, lat=37.769335 )
sf_map <- get_map(sf_center_point)
ggmap(sf_map)
# ggplot() +
ggmap(sf_map) +
geom_point(data=sfhomes, aes(x=lon, y=lat, col=totvalue))
# Get the center point of the data
sf_ctr <- c(lon = mean(sfhomes$lon), lat = mean(sfhomes$lat))
sf_ctr  # take a look
# create the map - setting the zoom level to 12
sf_basemap <- get_map(sf_ctr, source="stamen", maptype="toner-lite", zoom=12)
ggmap(sf_basemap) +
geom_point(data=sfhomes, aes(x=lon, y=lat, col=totvalue))
bart <- read.csv("./data/bart.csv")
# take a look
head (bart)
sfmap_with_bart <- ggmap(sf_basemap) +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red", size=3)
sfmap_with_bart
landmarks <- read.csv("./data/landmarks.csv")
head(landmarks)
#ggplot() +
#  geom_point(aes(lon, lat, col=totvalue), data = sfhomes2010_15 )  +
#  facet_wrap(~ SalesYear)
sfmap_bart_landmarks <- ggplot() +
geom_point(data=sfhomes15, aes(x=lon, y=lat))  +
geom_point(data=bart, aes(x=X,y=Y), col="red", size=3) +
geom_point(data=landmarks, aes(x=X,y=Y), shape=22,
col="black", fill="grey", size=4)
sfmap_bart_landmarks
head(landmarks)
sfhomes15_sp <- sfhomes15  # Make a copy - why?
class(sfhomes15_sp)  # check the class of the object
coordinates(sfhomes15_sp) <- c('lon','lat')  #  Make it spatial
#  ORDER MATTERS!!
class(sfhomes15_sp)  # check the class of the object
coordinates(sfhomes15_sp)
str(sfhomes15) # the data frame
summary(sfhomes15_sp)
head(sfhomes15_sp@data)
class(sfhomes15_sp@data)
sfhomes15_sp@bbox
bbox(sfhomes15_sp)
head(sfhomes15_sp@coords)
head(sfhomes15_sp$lat)
head(sfhomes15_sp$lon)
sfhomes15_sp@proj4string
proj4string(sfhomes15_sp)
library(rgdal)
# See what file types are supported by rgdal drivers
# ogrDrivers()$name
sfboundary <- readOGR(dsn="data",layer="sf_boundary")
# or
# sfboundary <- readOGR("data","sf_boundary")
# but not
#sfboundary <- readOGR(dsn="data/",layer="sf_boundary")
sfboundary_lonlat <- spTransform(sfboundary, CRS("+init=epsg:4326"))
proj4string(sfhomes15_sp) == proj4string(sfboundary_lonlat)
plot(sfboundary_lonlat)
points(sfhomes15_sp, col="red")
# Define the CRS with the parameter string
proj4string(sfhomes15_sp) <- CRS("+proj=longlat
+ellps=WGS84 +datum=WGS84 +no_defs")
# Define the CRS with an EPSG code for WGS84
proj4string(sfhomes15_sp) <- CRS("+init=epsg:4326")
proj4string(sfboundary)
proj4string(sfhomes15_sp)
proj4string(sfboundary) == proj4string(sfhomes15_sp)
sfboundary_lonlat <- spTransform(sfboundary, CRS("+init=epsg:4326"))
plot(sfboundary_lonlat)
points(sfhomes15_sp, col="red")
proj4string(sfhomes15_sp) == proj4string(sfboundary_lonlat)
# Define the CRS
proj4string(sfhomes15_sp) <- CRS("+init=epsg:4326")
#Transform the CRS
sfboundary_lonlat <- spTransform(sfboundary, CRS("+init=epsg:4326"))
# Convert the DF to a SPDF
coordinates(landmarks) <-c("X","Y")
# Define the CRS with an EPSG code for Web mercator
proj4string(landmarks) <- CRS("+init=epsg:3857")
# Transform the CRS to WGS84
landmarks_lonlat <- spTransform(landmarks, CRS("+init=epsg:4326"))
# map it
plot(sfboundary_lonlat)
points(sfhomes15_sp, col="red")
points(landmarks_lonlat, col="green")
landmarks
landmarks@data
landmarks@data$name
paste0(landmarks@data$name, ',  San Francisco, CA'
)
#prep our names for geocoding with the Google Maps API
place_names = paste0(landmarks@data$name, ',  San Francisco, CA')
geocode(place_names)
?geocode
geocode(place_names)$lat
landmarks_lonlat@data
landmarks_lonlat@coords
#transformed coords
landmarks_lonlat@coords
#geocoded coords
geocode_coords
#prep our names for geocoding with the Google Maps API
place_names = paste0(landmarks@data$name, ',  San Francisco, CA')
#geocode them
geocode_coords = geocode(place_names)
#transformed coords
landmarks_lonlat@coords
#geocoded coords
geocode_coords
geocode_coords
matrix(geocode_coords)
cbind(geocode_coords$lon, geocode_coords$lat)
#transformed coords
landmarks_lonlat@coords
#geocoded coords
geocode_coords
#transformed coords
landmarks_lonlat@coords
#geocoded coords
cbind(geocode_coords$lon, geocode_coords$lat)
sfhomes15 <- subset(sfhomes, as.numeric(SalesYear) == 2015)
sfhomes15_sp <- sfhomes15  # Make a copy - why?
class(sfhomes15_sp)  # check the class of the object
coordinates(sfhomes15_sp) <- c('lon','lat')  #  Make it spatial
#  ORDER MATTERS!!
class(sfhomes15_sp)  # check the class of the object
tmap_mode("view")
tm_basemap("Stamen.Watercolor") +
tm_shape(sfbounday_lonlat) +
tm_polygons(border.col="black") +
tm_shape(sfhomes15_sp) +
tm_dots(col="totvalue", size=.25, title = "San Francisco Property Values (2015)")
tm_tiles("Stamen.TonerLabels")
tmap_mode("view")
tm_basemap("Stamen.Watercolor") +
tm_shape(sfbounday_lonlat) +
tm_polygons(border.col="black") +
tm_shape(sfhomes15_sp) +
tm_dots(col="totvalue", size=.25, title = "San Francisco Property Values (2015)") +
tm_tiles("Stamen.TonerLabels")
tmap::tm_basemap('Stamen.Watercolor')
tmap_mode('view')
library(tmap)
tmap_mode('view')
tmap::tm_basemap('Stamen.Watercolor')
tmap_mode("view")
tm_basemap("Stamen.Watercolor") +
tm_shape(sfbounday_lonlat) +
tm_polygons(border.col="black") +
tm_shape(sfhomes15_sp) +
tm_dots(col="totvalue", size=.25, title = "San Francisco Property Values (2015)") +
tm_tiles("Stamen.TonerLabels")
tmap_mode("view")
tm_basemap("Stamen.Watercolor") +
tm_shape(sfboundary_lonlat) +
tm_polygons(border.col="black") +
tm_shape(sfhomes15_sp) +
tm_dots(col="totvalue", size=.25, title = "San Francisco Property Values (2015)") +
tm_tiles("Stamen.TonerLabels")
tmap_mode("view")
tm_basemap("Stamen.Watercolor") +
tm_shape(sfhomes15_sp) +
tm_dots(col="totvalue", size=.25, title = "San Francisco Property Values (2015)") +
tm_tiles("Stamen.TonerLabels")
